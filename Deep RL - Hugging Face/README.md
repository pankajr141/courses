# Introduction

This course focuses on easy to use theory and practicle through collab notebooks \
[https://huggingface.co/learn/deep-rl-course/unit0/introduction](https://huggingface.co/learn/deep-rl-course/unit0/introduction)

All models will be pushed into huggingface and can be seen in [Leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard), to search for model used in this repo select ENV, type pankajr141 under userid and click "Search My models" 

# Model collection
Below link contains the location where all model build using this repo are stored

[Hugging Face Model Collection for this course](https://huggingface.co/collections/pankajr141/huggingface-deeprl-6780de9f81e69ba91aee9019)

# Notebooks

* [Unit 1 - Introduction to Deep Reinforcement Learning](https://nbviewer.org/github/pankajr141/courses/blob/main/Deep%20RL%20-%20Hugging%20Face/notebooks/unit1/unit1.ipynb) \
Initial Unit to interact with gymnasium env ang train a PPO model using stablebaseline3
> <b>Env -</b> [LunarLander-v2](https://gymnasium.farama.org/environments/box2d/lunar_lander/) [gymnasium] \
> <b>Lib -</b> [stable_baselines3](https://stable-baselines3.readthedocs.io/en/master/index.html) \
> <b>Algo -</b> [PPO](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html)

* [Unit 1 Bonus - Introduction to Deep Reinforcement Learning with Huggy](https://nbviewer.org/github/pankajr141/courses/blob/main/Deep%20RL%20-%20Hugging%20Face/notebooks/unit1_bonus.ipynb) \
Bonus unit where we interact with Unity based Env and train RL model using PPO
> <b>Env -</b> [Huggy](https://github.com/huggingface/Huggy) [Unity] \
> <b>Lib -</b> [MLAgents](https://github.com/Unity-Technologies/ml-agents) \
> <b>Algo -</b> PPO
